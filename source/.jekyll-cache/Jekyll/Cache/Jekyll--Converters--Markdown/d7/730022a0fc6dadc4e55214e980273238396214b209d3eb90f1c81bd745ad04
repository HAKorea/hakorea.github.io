I"<p>The <code>ffmpeg</code> integration allows other Home Assistant integrations to process video and audio streams. This integration supports all FFmpeg versions since 3.0.0; if you have an older version, please update.</p>
<div class='note'>
<p>You need the <code>ffmpeg</code> binary in your system path. On Debian 8 or Raspbian (Jessie) you can install it from <a href="https://backports.debian.org/Instructions/">debian-backports</a>. If you want <a href="https://trac.ffmpeg.org/wiki/HWAccelIntro">hardware acceleration</a> support on a Raspberry Pi, you will need to build from source by yourself. Windows binaries are available on the <a href="http://www.ffmpeg.org/">FFmpeg</a> website.</p>
</div>
<div class='note'>
<p>If you are using <a href="/hassio/">Hass.io</a> then just move forward to the configuration as all requirements are already fulfilled.</p>
</div>
<h2>Configuration</h2>
<p>To set it up, add the following information to your <code>configuration.yaml</code> file:</p>
<pre><code class="language-yaml">ffmpeg:
</code></pre>
<div class="config-vars">
  <h3><a class="title-link" name="configuration-variables" href="#configuration-variables"></a> Configuration Variables</h3>
  <dl class=''><dt><a class='title-link' name='ffmpeg_bin' href='#ffmpeg_bin'></a> ffmpeg_bin</dt><dd><p class='desc'><span class='type'>(<span class='string'>string</span>)</span><span class='required'>(Optional)</span><span class='description'><p>The name or path to the <code>ffmpeg</code> binary.</p>
</span></p><p class='default'>
Default value: <p>ffmpeg</p>
</p></dd></dl>
</div>
<h3>Raspbian Debian Jessie Lite Installations</h3>
<p>To get the binary on Raspbian Debian Jessie Lite on a RPi you need to perform the following:</p>
<pre><code class="language-bash">sudo echo &quot;deb http://ftp.debian.org/debian jessie-backports main&quot; &gt;&gt; /etc/apt/sources.list
sudo apt-get update
sudo apt-get -t jessie-backports install ffmpeg
</code></pre>
<p>We can use now following in the configuration:</p>
<pre><code class="language-yaml">ffmpeg:
  ffmpeg_bin: /usr/bin/ffmpeg
</code></pre>
<h3>Troubleshooting</h3>
<p>In most cases, <code>ffmpeg</code> automatically detects all needed options to read a video or audio stream or file. But it is possible in rare cases that you will need to set options to help <code>ffmpeg</code> out.</p>
<p>First, check that your stream is playable by <code>ffmpeg</code> outside of Home Assistant with (use option <code>-an</code> or <code>-vn</code> to disable video or audio stream):</p>
<pre><code class="language-bash">ffmpeg -i INPUT -an -f null -
</code></pre>
<p>Now you should be able to see what is going wrong. The following list contains some common problems and solutions:</p>
<ul>
<li><code>[rtsp @ ...] UDP timeout, retrying with TCP</code>: You need to set an RTSP transport in the configuration with: <code>input: -rtsp_transport tcp -i INPUT</code></li>
<li><code>[rtsp @ ...] Could not find codec parameters for stream 0 (Video: ..., none): unspecified size</code>: FFmpeg needs more data or time for autodetection (the default is 5 seconds). You can set the <code>analyzeduration</code> and/or <code>probesize</code> options to experiment with giving FFmpeg more leeway. If you find the needed value, you can set it with: <code>input: -analyzeduration xy -probesize xy -i INPUT</code>. More information about this can be found <a href="https://www.ffmpeg.org/ffmpeg-formats.html#Description">here</a>.</li>
</ul>
<h4>USB cameras</h4>
<p>For <code>INPUT</code> a valid source is needed. A USB camera is an easy way to test your video setup. To get all available USB cameras connected to the system, e.g., use the v4l2 tools on a Linux machine.</p>
<pre><code class="language-bash">$ v4l2-ctl --list-devices
UVC Camera (046d:0825) (usb-0000:00:14.0-1):
  /dev/video1

Integrated Camera (usb-0000:00:14.0-10):
  /dev/video0
</code></pre>
<p>Record a test video with your USB device <code>/dev/video1</code>:</p>
<pre><code class="language-bash">$ ffmpeg -i /dev/video1 -codec:v libx264 -qp 0 lossless.mp4
[...]
Input #0, video4linux2,v4l2, from '/dev/video1':
  Duration: N/A, start: 43556.376974, bitrate: 147456 kb/s
    Stream #0:0: Video: rawvideo (YUY2 / 0x32595559), yuyv422, 640x480, 147456 kb/s, 30 fps, 30 tbr, 1000k tbn, 1000k tbc
[...]
Output #0, mp4, to 'lossless.mp4':
  Metadata:
    encoder         : Lavf57.41.100
    Stream #0:0: Video: h264 (libx264) ([33][0][0][0] / 0x0021), yuv422p, 640x480, q=-1--1, 30 fps, 15360 tbn, 30 tbc
    Metadata:
      encoder         : Lavc57.48.101 libx264
    Side data:
      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1
Stream mapping:
  Stream #0:0 -&gt; #0:0 (rawvideo (native) -&gt; h264 (libx264))
Press [q] to stop, [?] for help
frame=  223 fps= 40 q=-1.0 Lsize=   16709kB time=00:00:07.40 bitrate=18497.5kbits/s dup=58 drop=0 speed=1.32x
</code></pre>
:ET
I"[6<div class='note warning'>
<p>The Snips Console no longer available due to acquisition by Sonos. For more details, read the <a href="https://forum.snips.ai/t/important-message-regarding-the-snips-console/4145">announcement on the Snips forum</a>.</p>
</div>
<p>The <a href="https://www.snips.ai">Snips Voice Platform</a> allows users to add powerful voice assistants to their Raspberry Pi devices without compromising on privacy. It runs 100% on-device, and does not require an internet connection. It features Hotword Detection, Automatic Speech Recognition (ASR), Natural Language Understanding (NLU) and Dialog Management.</p>
<p>The latest documentation can be found here: <a href="https://docs.snips.ai/">Snips Platform Documentation</a>.</p>
<p><img src="/images/screenshots/snips_modules.png" alt="Snips Modules" /></p>
<p>Snips takes voice or text as input and produces <em>intents</em> as output, which are explicit representations of an intention behind an utterance and which can subsequently be used by Home Assistant to perform appropriate actions.</p>
<p><img src="/images/screenshots/snips_nlu.png" alt="Snips Modules" /></p>
<h2>The Snips Voice Platform</h2>
<h3>Installation</h3>
<p>The Snips platform can be installed via the Snips APT/Debian repository.</p>
<pre><code class="language-bash">sudo apt-get update
sudo apt-get install -y dirmngr
sudo bash -c  'echo &quot;deb https://raspbian.snips.ai/$(lsb_release -cs) stable main&quot; &gt; /etc/apt/sources.list.d/snips.list'
sudo apt-key adv --fetch-keys https://raspbian.snips.ai/531DD1A7B702B14D.pub
sudo apt-get update
sudo apt-get install -y snips-platform-voice
</code></pre>
<p>Note that if the keyserver pgp.mit.edu is down then try to use another one in the 4th line, like pgp.surfnet.nl:</p>
<pre><code class="language-bash">sudo apt-key adv --keyserver pgp.surfnet.nl --recv-keys D4F50CDCA10A2849
</code></pre>
<h3>Creating an assistant</h3>
<p>Head over to the <a href="https://console.snips.ai">Snips Console</a> to create your assistant. Launch the training and download by clicking on the “Download Assistant” button.</p>
<p>The next step is to get the assistant to work on your device. Unzip and copy the <code>assistant</code> folder that you downloaded from the web console to the path. Assuming your downloaded <code>assistant</code> folder is on your desktop, just run:</p>
<pre><code class="language-bash">scp -r ~/Desktop/assistant pi@&lt;raspi_hostname.local_or_IP&gt;:/home/pi/.
</code></pre>
<p>Now ssh into your Raspberry Pi:</p>
<pre><code class="language-bash">ssh pi@&lt;raspi_hostname.local_or_IP&gt;
</code></pre>
<p>By default, this command is <code>ssh pi@raspberrypi.local</code>, if you are using the default Raspberry Pi hostname.</p>
<p>Then, move the assistant to the right folder:</p>
<pre><code class="language-bash">(pi) $ sudo mv /home/pi/assistant /usr/share/snips/assistant
</code></pre>
<p>Note that if you already have an assistant installed and wish to replace it then start by removing the previous one and then move the new one in its place:</p>
<pre><code class="language-bash">(pi) $ sudo rm -r /usr/share/snips/assistant
(pi) $ sudo mv /home/pi/assistant /usr/share/snips/assistant
</code></pre>
<h3>Running Snips</h3>
<p>Make sure that a microphone is plugged to the Raspberry Pi. If you are having trouble setting up audio, we have written a guide on <a href="https://docs.snips.ai/articles/raspberrypi/hardware/microphones">Raspberry Pi Microphones</a>.</p>
<p>Start the Snips Voice Platform by starting the <code>snips-*</code> services:</p>
<pre><code class="language-bash">sudo systemctl start &quot;snips-*&quot;
</code></pre>
<p>Snips is now ready to take voice commands from the microphone. To trigger the listening, simply say</p>
<p><em>Hey Snips</em></p>
<p>followed by a command, e.g.</p>
<p><em>Set the lights to green in the living room</em></p>
<p>As the Snips Platform parses this query into an intent, it will be published on MQTT, on the <code>hermes/intent/&lt;intentName&gt;</code> topic. The Snips Home Assistant integration subscribes to this topic, and handles the intent according to the rules defined in <code>configuration.yaml</code> file, as explained below.</p>
<h4>Optional: specifying an external MQTT broker</h4>
<p>By default, Snips runs its own MQTT broker. But we can also tell Snips to use an external broker by specifying this when launching Snips. In this case, we need to specify this in the <code>/etc/snips.toml</code> configuration file. For more information on configuring this, see the <a href="https://docs.snips.ai/articles/platform/platform-configuration">Snips Platform Configuration</a> article.</p>
<h2>Home Assistant configuration</h2>
<div class="config-vars">
  <h3><a class="title-link" name="configuration-variables" href="#configuration-variables"></a> Configuration Variables</h3>
  <dl class=''><dt><a class='title-link' name='feedback_sounds' href='#feedback_sounds'></a> feedback_sounds</dt><dd><p class='desc'><span class='type'>(<span class='string'>string</span>)</span><span class='required'>(Optional)</span><span class='description'><p>Turn on feedbacks sounds for Snips.</p>
</span></p><p class='default'>
Default value: <p>false</p>
</p></dd><dt><a class='title-link' name='site_ids' href='#site_ids'></a> site_ids</dt><dd><p class='desc'><span class='type'>(<span class='string'>string</span>)</span><span class='required'>(Optional)</span><span class='description'><p>A list of siteIds if using multiple Snips instances. Used to make sure feedback is toggled on or off for all sites.</p>
</span></p></dd><dt><a class='title-link' name='probability_threshold' href='#probability_threshold'></a> probability_threshold</dt><dd><p class='desc'><span class='type'>(<span class='float'>float</span>)</span><span class='description'><p>Threshold for intent probability. Range is from 0.00 to 1.00, 1 being highest match. Intents under this level are discarded.</p>
</span></p></dd></dl>
</div>
<h3>Specifying the MQTT broker</h3>
<p>Messages between Snips and Home Assistant are passed via MQTT. We can either point Snips to the MQTT broker used by Home Assistant, as explained above, or tell Home Assistant which <a href="/docs/mqtt/">MQTT broker</a> to use by adding the following entry to the <code>configuration.yaml</code> file:</p>
<pre><code class="language-yaml">mqtt:
  broker: MQTT_BROKER_IP
  port: MQTT_BROKER_PORT
</code></pre>
<p>By default, Snips runs an MQTT broker on port 9898. So if we wish to use this broker, and if Snips and Home Assistant run on the same device, the entry will look as follows:</p>
<pre><code class="language-yaml">mqtt:
  broker: 127.0.0.1
  port: 9898
</code></pre>
<p>Alternatively, MQTT can be configured to bridge messages between servers if using a custom MQTT broker such as <a href="https://mosquitto.org/">mosquitto</a>.</p>
<h3>Triggering actions</h3>
<p>In Home Assistant, we trigger actions based on intents produced by Snips using the <a href="/integrations/intent_script"><code>intent_script</code></a> component. For instance, the following block handles a <code>ActivateLightColor</code> intent to change light colors:</p>
<p>Note: If your Snips action is prefixed with a username (e.g., <code>john:playmusic</code> or <code>john__playmusic</code>), the Snips integration in Home Assistant will try and strip off the username. Bear this in mind if you get the error <code>Received unknown intent</code> even when what you see on the MQTT bus looks correct. Internally the Snips integration is trying to match the non-username version of the intent (i.e., just <code>playmusic</code>).</p>
<pre><code class="language-yaml">snips:

intent_script:
  ActivateLightColor:
    action:
      - service: light.turn_on
        data_template:
          entity_id: light.{{ objectLocation | replace(&quot; &quot;,&quot;_&quot;) }}
          color_name: {{ objectColor }}
</code></pre>
<p>In the <code>data_template</code> block, we have access to special variables, corresponding to the slot names for the intent. In the present case, the <code>ActivateLightColor</code> has two slots, <code>objectLocation</code> and <code>objectColor</code>.</p>
<h3>Special slots</h3>
<p>Several special values for slots are populated with the <code>siteId</code> the intent originated from and the probability value for the intent, the <code>sessionId</code> generate by the dialogue manager, and <code>slote_name</code> raw which will contain the raw, uninterpreted text of the slot value.</p>
<p>In the above example, the slots are plain strings. However, Snips has a duration builtin value used for setting timers and this will be parsed to a seconds value.</p>
<p>In this example if we had an intent triggered with ‘Set a timer for five minutes’, <code>duration:</code> would equal 300 and <code>duration_raw:</code> would be set to ‘five minutes’. The duration can be easily used to trigger Home Assistant events and the <code>duration_raw:</code> could be used to send a human readable response or alert.</p>
<pre><code class="language-yaml">SetTimer:
  speech:
    type: plain
    text: 'Set a timer'
  action:
    service: script.set_timer
    data_template:
      name: &quot;{{ timer_name }}&quot;
      duration: &quot;{{ timer_duration }}&quot;
      siteId: &quot;{{ site_id }}&quot;
      sessionId: &quot;{{ session_id }}&quot;
      duration_raw: &quot;{{ raw_value }}&quot;
      probability: &quot;{{ probability }}&quot;
</code></pre>
<h3>Sending TTS Notifications</h3>
<p>You can send TTS notifications to Snips using the <code>snips.say</code> and <code>snips.say_action</code> services. <code>say_action</code> starts a session and waits for user response, “Would you like me to close the garage door?”, “Yes, close the garage door”.</p>
<h4>Service <code>snips.say</code></h4>
<table>
<thead>
<tr>
<th>Service data attribute</th>
<th>Optional</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>text</code></td>
<td>no</td>
<td>Text to say.</td>
</tr>
<tr>
<td><code>site_id</code></td>
<td>yes</td>
<td>Site to use to start session.</td>
</tr>
<tr>
<td><code>custom_data</code></td>
<td>yes</td>
<td>custom data that will be included with all messages in this session.</td>
</tr>
</tbody>
</table>
<h4>Service <code>snips.say_action</code></h4>
<table>
<thead>
<tr>
<th>Service data attribute</th>
<th>Optional</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>text</code></td>
<td>no</td>
<td>Text to say.</td>
</tr>
<tr>
<td><code>site_id</code></td>
<td>yes</td>
<td>Site to use to start session.</td>
</tr>
<tr>
<td><code>custom_data</code></td>
<td>yes</td>
<td>custom data that will be included with all messages in this session.</td>
</tr>
<tr>
<td><code>can_be_enqueued</code></td>
<td>yes</td>
<td>If True, session waits for an open session to end, if False session is dropped if one is running.</td>
</tr>
<tr>
<td><code>intent_filter</code></td>
<td>yes</td>
<td>Array of Strings - A list of intents names to restrict the NLU resolution to on the first query.</td>
</tr>
</tbody>
</table>
<h3>Snips Support</h3>
<p>There is an active <a href="https://forum.snips.ai">Forum</a> for further support.</p>
<h3>Configuration Examples</h3>
<h4>Turn on a light</h4>
<pre><code class="language-yaml">intent_script:
  turn_on_light:
    speech:
      type: plain
      text: 'OK, turning on the light'
    action:
      service: light.turn_on
</code></pre>
<h5>Open a Garage Door</h5>
<pre><code class="language-yaml">intent_script:
  OpenGarageDoor:
    speech:
      type: plain
      text: 'OK, opening the garage door'
    action:
      - service: cover.open_cover
        data:
          entity_id: garage_door
</code></pre>
<h5>Intiating a query</h5>
<p>Here is a more complex example. The automation is triggered if the garage door is open for more than 10 minutes. Snips will then ask you if you want to close it and if you respond with something like “Close the garage door” it will do so. Unfortunately there is no builtin support for yes and no responses.</p>
<pre><code class="language-yaml">automation:
  garage_door_has_been_open:
    trigger:
     - platform: state
        entity_id: binary_sensor.my_garage_door_sensor
        from: 'off'
        to: 'on'
        for:
          minutes: 10
    sequence:
      service: snips.say_action
        data:
          text: 'Garage door has been open 10 minutes, would you like me to close it?'
          intent_filter:
            - closeGarageDoor

# This intent is fired if the user responds with the appropriate intent after the above notification
intent_script:
  closeGarageDoor:
    speech:
      type: plain
      text: 'OK, closing the garage door'
    action:
      - service: script.garage_door_close
</code></pre>
<h5>Weather</h5>
<p>So now you can open and close your garage door, let’s check the weather. Add the Weather by Snips Skill to your assistant. Create a weather sensor, in this example <a href="/integrations/darksky">Dark Sk</a> and the <code>api_key</code> in the <code>secrets.yaml</code> file.</p>
<pre><code class="language-yaml">- platform: darksky
  name: &quot;Dark Sky Weather&quot;
  api_key: !secret dark_sky_key
  scan_interval:
    minutes: 10
  monitored_conditions:
    - summary
    - hourly_summary
    - temperature
    - temperature_max
    - temperature_min
</code></pre>
<p>Then add this to your configuration file.</p>
<pre><code class="language-yaml">intent_script:
  searchWeatherForecast:
    speech:
      type: plain
      text: &gt;
        The weather is currently
        {{ states('sensor.dark_sky_weather_temperature') | round(0) }}
        degrees outside and {{ states('sensor.dark_sky_weather_summary') }}.
        The high today will be
        {{ states('sensor.dark_sky_weather_daily_high_temperature') | round(0)}}
        and {{ states('sensor.dark_sky_weather_hourly_summary') }}
</code></pre>
:ET